import streamlit as st
import pandas as pd
import subprocess
import Qwen_eval as evaluate
import matplotlib.pyplot as plt

### Implementation of running `.py` files using a simple click.
def button_run(button_name: str, file_name: str, enable_output: bool = False):
    if st.button(button_name):
        with st.spinner("Running..."):
            st.divider()        
            
            result = subprocess.run(['python', file_name], capture_output=True, text=True)
            
            stdout = result.stdout
            stderr = result.stderr
            
            st.markdown("##### **:green[Done!]**")        
            if stdout and enable_output:
                st.code(stdout)
            
            if stderr:
                st.markdown("##### **:red[Error:]**")
                st.code(stderr, language='bash')
            st.divider()

def plot():
    
    def plot_accuracy(accuracy):
        criteria = list(accuracy.keys())
        labels = ["Graph RAG", "Naive RAG", "Tie"]
        colors = ['#D0DD97', '#E6B745', '#DDDDDD']

        fig, axs = plt.subplots(1, 4, figsize=(18, 4))
        fig.suptitle('Evaluation of different models')

        for i, criterion in enumerate(criteria):
            values = [accuracy[criterion][label] for label in labels]
            axs[i].bar(labels, values, color=colors)
            axs[i].set_xlabel('Models')
            axs[i].set_ylabel('Win Rate')
            axs[i].set_title(criterion)
            axs[i].set_ylim([0, 1])  

        plt.tight_layout(rect=[0, 0, 1, 0.95])
        st.pyplot(fig)    

    global_file_path = "result/global-answers.json"
    naive_file_path = "result/naive-answers.json"

    if st.button("Run Evaluation"):
        with st.spinner("Evaluating..."):
            global_data = evaluate.read_json(global_file_path)
            total_questions = sum(len(cases) for tasks in global_data.values() for cases in tasks.values())
            progress_bar = st.progress(0)
            processed_questions = 0

            def update_progress(increment):
                nonlocal processed_questions
                processed_questions += increment
                progress_bar.progress(processed_questions / total_questions)

            accuracy = evaluate.main(global_file_path, naive_file_path, progress_callback=update_progress)
            st.success("Evaluation Complete!")
            plot_accuracy(accuracy)

st.title(' A demo of the project ')
st.html('<h4 align="center" style="color:red"> QI, Xixian (1155215638) </h4>')

##########

st.header('I. Project File Overview')
st.text('Some files may be missing as files/folder are created during execution.\nThis section is only for reference.')

data = {
  "File Name": ["/rawWhitePapers", "/txtWhitePapers", "web_crawl.py", "url.json", "pdfToTxt.py", "Qwen_phase2_global.py", "Qwen_phase2_naive.py", "questions.json", "/result", "Qwen_eval.py", "demo.py"],
  "Explanation": ["pdf-format of tutorials", "txt-format of tutorials", "crwal news for the web page", "lists of target news", "convert pdf to txt of the paper folder", "Insert and query via nano graphRAG", "Insert and query via naive RAG", "lists of questions generated by LLM", "store the outputs of each model", "Evaluate the outcome via LLM", "self"]
}
df = pd.DataFrame(data)
st.table(df)

##########

st.header('II. Execution')
st.markdown('In this section, we go through the codes in this project, from data preprocessing to result display.')

st.subheader('II(a) Crawl News')
st.markdown('Before crawling contents from the news, we need to specify the :red[url] and the :red[css element] on `url.json`. \
             Each item should follow the format as:')
st.code('{"url": "www.example.com", "css":[".whiteListClass1", ".whiteListClass2"]},', language='json')
st.markdown('The crawler uses a non-llm based preprocessing method and already includes all news on RootData. Then, we may run the crawler:')
button_run('Crawl News', 'web_crawl.py')

st.subheader('II(b) Pdf to Txt')
st.markdown('In addition to the news, we have collected various web3 whitepapers as a corpus, including the well-known Bitcoin,\
            Ethereum, and the spotlighted Dogecoin. However, these material requires a conversion to raw texts. A simple solution\
            is to call the Python module `PyPDF2:`')
button_run('Convert Pdf', 'pdfToTxt.py', enable_output=True)

st.subheader('II(c) Run Graph RAG')
st.markdown('Finally, we can start to run our model. As the runtime is long (~2-3h), we only attach our command below:')
st.code('python Qwen_phase2_global.py', language='bash')
st.markdown('Once successfully run, a file `global-answers.json` should be created under the folder `/results`.')

st.subheader('II(d) Run Naive RAG as baseline')
st.markdown('This process is nothing different, except calling :blue[naive] parameter during the query. As the runtime is also\
            long (~2-3h), we only attach our command below:')
st.code('python Qwen_phase2_naive.py', language='bash')
st.markdown('Once successfully run, a file `naive-answers.json` should be created under the folder `/results`.')

st.subheader('II(e) Evaluate and Plot results')
st.markdown('Before plotting the final outcome, we ask the LLm to generate a set of questions as queries on high-level understanding.\
            Given a short description of the datasets, the questions are generated in `questions.json`. One sample input is as follows:')
st.code('''  {
  "Crypto Enthusiasts": {
    "Exploring Dogecoin's Community and Trends": [
      "What role does social media play in the Dogecoin community?",
      "How have celebrity endorsements influenced Dogecoin's popularity?",
      ...
      ]
    }
  }''', language='json')
st.markdown('''It\'s time to evaluate and visualize the outcome of our experiment. Four metrics are selected:\\
            - **Conciseness**: The response that is more concise and to the point. \\
            - **Information Coverage**: The response that covers the most relevant information. \\
            - **Relevance**: The response that is most relevant to the original question. \\
            - **Diversity**: The response that provides a more diverse range of information or perspectives.''')
st.markdown("The LLM evaluate the responses based on the above criteria and provide the winner for each criterion.")
plot()

